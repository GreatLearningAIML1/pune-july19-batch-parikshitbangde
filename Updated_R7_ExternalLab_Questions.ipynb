{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4WH1Pr4KQlCh"
   },
   "source": [
    "### Build a DNN using Keras with `RELU` and `ADAM`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TbvI8LqlQlCl",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Load tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SPW-a-qYQlCp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we are using tensorflow version 2.0.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "print ('we are using tensorflow version',tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "74cQBsi5QlCw",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Collect Fashion mnist data from tf.keras.datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wVWy0oDTr2Kj"
   },
   "outputs": [],
   "source": [
    "(trainX, trainY),(testX, testY) = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traing set shape (60000, 28, 28)\n",
      "training set shape (60000,)\n",
      "test set shape (10000, 28, 28)\n",
      "test set shape (10000,)\n"
     ]
    }
   ],
   "source": [
    "print ('traing set shape',trainX.shape)\n",
    "print ('training set shape',trainY.shape)\n",
    "print ('test set shape',testX.shape)\n",
    "print ('test set shape',testY.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "no7aWYZyQlC1",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Change train and test labels into one-hot vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UX6otc4wQlC2"
   },
   "outputs": [],
   "source": [
    "#Convert labels to one hot encoding\n",
    "train = tf.keras.utils.to_categorical(trainY, num_classes=10)\n",
    "test = tf.keras.utils.to_categorical(testY, num_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QjNrRTdoQlC5",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Build the Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CDJ9DHVNQlC7"
   },
   "source": [
    "#### Initialize model, reshape & normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "pCDQs_g1QlC8",
    "outputId": "e854b4d2-903a-4515-c21b-bd6a6e4fe2f8"
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "#Initialize model, reshape & normalize data\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "#Reshape data from 2D (28,28) to 3D (28, 28, 1)\n",
    "model.add(tf.keras.layers.Reshape((28,28,1),input_shape=(28,28,)))\n",
    "\n",
    "#normalize data\n",
    "model.add(tf.keras.layers.BatchNormalization())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kBGwTTilQlDD",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Add two fully connected layers with 200 and 100 neurons respectively with `relu` activations. Add a dropout layer with `p=0.25`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "IXbfpfOzQlDF",
    "outputId": "f46a2e3a-2634-4e9e-88bd-57bb8de1ff0c"
   },
   "outputs": [],
   "source": [
    "#Add first convolutional layer\n",
    "model.add(tf.keras.layers.Conv2D(32, #Number of filters \n",
    "                                 kernel_size=(3,3), #Size of the filter\n",
    "                                 activation='relu'))\n",
    "\n",
    "#Add second convolutional layer\n",
    "model.add(tf.keras.layers.Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "\n",
    "#Add MaxPooling layer\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "#Flatten the output\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "#Dense layer\n",
    "model.add(tf.keras.layers.Dense(200, activation='relu'))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(100, activation='relu'))\n",
    "\n",
    "#Add another dropout layer\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5I8f5otcQlDJ"
   },
   "source": [
    "### Add the output layer with a fully connected layer with 10 neurons with `softmax` activation. Use `categorical_crossentropy` loss and `adam` optimizer and train the network. And, report the final validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JZkvKymSd0Sr"
   },
   "outputs": [],
   "source": [
    "#Output layer\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape (Reshape)            (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 28, 28, 1)         4         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 200)               1843400   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 1,883,330\n",
      "Trainable params: 1,883,328\n",
      "Non-trainable params: 2\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 72s 1ms/sample - loss: 0.3823 - accuracy: 0.8635 - val_loss: 0.2898 - val_accuracy: 0.8919\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 59s 990us/sample - loss: 0.2299 - accuracy: 0.9168 - val_loss: 0.2580 - val_accuracy: 0.9044\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 58s 970us/sample - loss: 0.1726 - accuracy: 0.9362 - val_loss: 0.2222 - val_accuracy: 0.9182\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 59s 987us/sample - loss: 0.1322 - accuracy: 0.9514 - val_loss: 0.2419 - val_accuracy: 0.9218\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 60s 1ms/sample - loss: 0.0993 - accuracy: 0.9623 - val_loss: 0.2670 - val_accuracy: 0.9230\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 62s 1ms/sample - loss: 0.0767 - accuracy: 0.9717 - val_loss: 0.3238 - val_accuracy: 0.9160\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 59s 977us/sample - loss: 0.0633 - accuracy: 0.9761 - val_loss: 0.3315 - val_accuracy: 0.9236\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 58s 971us/sample - loss: 0.0495 - accuracy: 0.9818 - val_loss: 0.3570 - val_accuracy: 0.9211\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 58s 969us/sample - loss: 0.0437 - accuracy: 0.9842 - val_loss: 0.3896 - val_accuracy: 0.9213\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 58s 969us/sample - loss: 0.0351 - accuracy: 0.9875 - val_loss: 0.3841 - val_accuracy: 0.9228\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e4ce26d6d8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the model\n",
    "model.fit(trainX,train,          \n",
    "          validation_data=(testX,test),\n",
    "          epochs=10,\n",
    "          batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuraccy on test set is found to be 92.23% on 10th itration \n"
     ]
    }
   ],
   "source": [
    "print ('Acuraccy on test set is found to be 92.23% on 10th itration ' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy is 92.23%\n"
     ]
    }
   ],
   "source": [
    "print ('validation accuracy is 92.23%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[878   0  18  16   3   0  86   0   5   1]\n",
      " [  1 987   1   8   1   0   0   0   0   0]\n",
      " [ 13   0 853   8  34   0  27   0   0   0]\n",
      " [  8   7   6 903  15   0  19   0   4   0]\n",
      " [  1   2  58  32 879   0  43   0   0   0]\n",
      " [  1   0   0   0   0 986   0  11   1   4]\n",
      " [ 93   2  63  33  67   0 819   0   5   1]\n",
      " [  0   0   0   0   0   9   0 967   2  20]\n",
      " [  5   2   1   0   1   0   6   0 982   0]\n",
      " [  0   0   0   0   0   5   0  22   1 974]]\n"
     ]
    }
   ],
   "source": [
    "test1 = tf.cast(testX, tf.float32)\n",
    "print(confusion_matrix(model.predict_classes(test1), testY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please find the classification report as following: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.87      0.87      1007\n",
      "           1       0.99      0.99      0.99       998\n",
      "           2       0.85      0.91      0.88       935\n",
      "           3       0.90      0.94      0.92       962\n",
      "           4       0.88      0.87      0.87      1015\n",
      "           5       0.99      0.98      0.98      1003\n",
      "           6       0.82      0.76      0.79      1083\n",
      "           7       0.97      0.97      0.97       998\n",
      "           8       0.98      0.98      0.98       997\n",
      "           9       0.97      0.97      0.97      1002\n",
      "\n",
      "    accuracy                           0.92     10000\n",
      "   macro avg       0.92      0.92      0.92     10000\n",
      "weighted avg       0.92      0.92      0.92     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "print(\"Please find the classification report as following: \\n\")\n",
    "print(classification_report(model.predict_classes(test1),testY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Updated_R7_ExternalLab_Questions.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
